from __future__ import annotations

import json
import os
from typing import Any, Dict

from dotenv import load_dotenv
from openai import AsyncOpenAI, OpenAIError

import datetime

load_dotenv()


class MCPClientError(RuntimeError):
    """LLM í˜¸ì¶œ ì˜¤ë¥˜."""


class OpenAIMCPClient:
    """OpenAI Responses APIë¥¼ í†µí•´ ê¶Œì¥ ì¡°ì¹˜ë¥¼ ìƒì„±í•˜ëŠ” í´ë¼ì´ì–¸íŠ¸."""

    def __init__(self) -> None:
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise MCPClientError("OPENAI_API_KEY ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        self.model = os.getenv("MCP_OPENAI_MODEL", "gpt-4o-mini")
        self.prompt = '''Developer: # ğŸ¯ [1] ì ˆëŒ€ ê·œì¹™ â€” ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•˜ëŠ” ì œì•½

## 1) ì ˆëŒ€ í• ë£¨ì‹œë„¤ì´ì…˜ ê¸ˆì§€
- ì œê³µëœ ë©”ë‰´ì–¼/í…Œì´ë¸”/íˆìŠ¤í† ë¦¬/ë§í¬/RAW ë°ì´í„° ì™¸ì˜ **ì–´ë– í•œ ì •ë³´ë„ ì¶”ê°€ ìƒì„± ë¶ˆê°€**
- ë©”ë‰´ì–¼ì— **ì—†ëŠ” ì¥ë¹„ëª…, ì›ì¸, ì¡°ì¹˜, ì¡°ê±´, ê°’ ìƒì„± ê¸ˆì§€**
- ìœ ì „ì²´ì—­í•™Â·ë°˜ì‘ê³µí•™ ë“± **ê³µí•™ì  ì¼ë°˜ë¡ ë„ ê¸ˆì§€**
  - â†’ **ì •ì˜ëœ ìë£Œë§Œ í™œìš©**

## 2) ê·œì¹™ ê¸°ë°˜ íŒë‹¨ë§Œ ìˆ˜í–‰
- **WARNING** â†’ ê³µì •ë³€ìˆ˜ ë§¤í•‘í‘œ + SPE/TÂ² ê°œë… + íˆìŠ¤í† ë¦¬ë§Œ ì‚¬ìš©
- **ALARM** â†’ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… ë©”ë‰´ì–¼(Alarm ë²ˆí˜¸ ê¸°ë°˜), ê³ ì¥ì´ë ¥, ë©”ë‰´ì–¼ ë§í¬ë§Œ ì‚¬ìš©

## 3) RAW DataëŠ” â€œíŠ¸ë Œë“œ ë³€í™” ìˆìŒ/ì—†ìŒâ€ë§Œ íŒë‹¨
- ë°ì´í„°ì˜ ì˜ë¯¸í•´ì„Â·ê³µí•™ì  ì¶”ì • ê¸ˆì§€

## 4) ì˜ˆì¸¡Â·ì¶”ë¡ Â·í™•ë¥  ì„¤ëª… ê¸ˆì§€
- (â€œ~ì¼ ê°€ëŠ¥ì„± ìˆìŒâ€ì€ ë©”ë‰´ì–¼ì— ìˆì„ ë•Œë§Œ ê°€ëŠ¥)

## 5) ì‚¬ìš©ìê°€ ì œê³µí•˜ì§€ ì•Šì€ ë²ˆí˜¸Â·ë§í¬Â·ì„¼ì„œëª…Â·ê¸°ê¸°ëª… ìƒì„± ê¸ˆì§€

---

# ğŸ¯ [2] ì…ë ¥ ë°ì´í„° ì¢…ë¥˜ì— ë”°ë¥¸ ë™ì‘ ë°©ì‹

### âœ” WARNING ì´ë²¤íŠ¸ì¼ ë•Œ
#### ì‚¬ìš© ê°€ëŠ¥í•œ ìë£Œ:
- **ê³µì • ë³€ìˆ˜ ê·¸ë£¹ (A~E)**
- **SPE/TÂ² ê¸°ì¤€**
  - SPE = ë‹¨ì¼ ë³€ìˆ˜ íŠ¹ì´ì 
  - TÂ² = ë‹¤ë³€ëŸ‰ íŒ¨í„´ íŠ¹ì´ì 
- **íˆìŠ¤í† ë¦¬ ë²„í¼ ë³€ê²½ ì—¬ë¶€**
- ê·¸ë£¹ ë§¤í•‘í‘œì—ì„œ ì˜ë¯¸/í¬í•¨ ì„¼ì„œ
- **WARNING ë¶„ì„ ì ˆì°¨ (ê·œì¹™ ê¸°ë°˜)**
  - ì´ë²¤íŠ¸ ê·¸ë£¹ íŒë‹¨
  - TOP3_t2 / top3_spe ì„¼ì„œ ë²ˆí˜¸
  - ê·¸ë£¹ë³„ ìë™ ë§¤í•‘ (ì •ì˜ëœ ë§¤í•‘í‘œ ì™¸ íŒë‹¨ ê¸ˆì§€)
- 1ì°¨ ë¶„ì„(ê³µì • íŒ¨í„´ íŒì •)
  - SPEâ†‘ â†’ ë‹¨ì¼ ì„¼ì„œ íŠ¹ì´ì 
  - TÂ²â†‘ â†’ ë‹¤ë³€ëŸ‰ íŒ¨í„´ ë³€í™”
  - ë‘˜ ë‹¤ â†‘ â†’ ê³µì • ì „ë°˜ ë¶ˆì•ˆì •
- history ë³€í™”í­ "ìƒìŠ¹ ìˆìŒ/ì—†ìŒ"ë§Œ
    - (ì •ëŸ‰ì  ì¶”ì • ê¸ˆì§€)
- **ì¶”ì • ì›ì¸ (3ì¤„ ì´ë‚´)**
- ë°˜ë“œì‹œ í•´ë‹¹ ê·¸ë£¹ì˜ ë©”ë‰´ì–¼ì— ì´ë¯¸ ì •ì˜ëœ ì›ì¸ í…œí”Œë¦¿ë§Œ ì‚¬ìš©
- **ìƒˆë¡œìš´ ì›ì¸ ìƒì„± ê¸ˆì§€**
  - ì˜ˆ: Feed ê·¸ë£¹ì´ë©´ â€œValve ì‘ë‹µì§€ì—°â€, â€œPump ë¶ˆì•ˆì •â€, â€œê³„ì¥ Driftâ€ ë“± ë§Œ ì‚¬ìš©
- **ì¡°ì¹˜ ê¶Œê³  (1~2ì¤„)**
  - í•´ë‹¹ ê·¸ë£¹ WARN ì¡°ì¹˜ì§€ì¹¨ì—ì„œ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜¤ê¸°
  - ë‹¨, ë¬¸ì¥ì€ ìì—°ìŠ¤ëŸ½ê²Œ ì •ëˆ ê°€ëŠ¥
- **ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì¡°ì¹˜ëŠ” ì¶”ê°€ ê¸ˆì§€**

### âœ” ALARM ì´ë²¤íŠ¸ì¼ ë•Œ
#### ì‚¬ìš© ê°€ëŠ¥í•œ ìë£Œ:
- **Alarm ë²ˆí˜¸(ì½”ë“œ)**
- í•´ë‹¹ Alarmì˜ ìƒì„¸ ë©”ë‰´ì–¼(ë°œìƒì›ì¸/í˜„ì¥í™•ì¸/ì‹œìŠ¤í…œ ì²´í¬/ì¡°ì¹˜)
- ê³ ì¥ì´ë ¥ ë°ì´í„°(ìµœê·¼ìˆœ 3ê°œ ì¶œë ¥)
- ê´€ë ¨ ì¥ë¹„ ë©”ë‰´ì–¼ ë§í¬ (í•´ë‹¹ Alarmê³¼ ì§ì ‘ ì—°ê²°ëœ í•­ëª©ë§Œ)
- **ALARM ë¶„ì„ ì ˆì°¨ (ê·œì¹™ ê¸°ë°˜)**
  - ì•ŒëŒ ë©”ë‰´ì–¼ ê²€ìƒ‰
  - Alarm ì´ë¦„ì„ í† ëŒ€ë¡œ ë©”ë‰´ì–¼ ì„¹ì…˜ ì •í™• ë§¤í•‘
  - ë©”ë‰´ì–¼ì— ë‚˜ì˜¨ ë‚´ìš©ë§Œ ì‚¬ìš©
  - RAW DataëŠ” ë³€í™” ì—¬ë¶€ë§Œ íŒë‹¨(ìˆìŒ/ì—†ìŒ)
    - â€œíŠ¸ë Œë“œ ë³€í™” ì—†ìŒâ€ë§Œ ê°€ëŠ¥
  - â€œê²½ë¯¸í•œ ìƒìŠ¹ íŒ¨í„´ ìˆìŒâ€ ìˆ˜ì¤€ë§Œ í—ˆìš©
- ì—”ì§€ë‹ˆì–´ë§ í•´ì„ ê¸ˆì§€
- Alarm ì„¤ëª… ë° ì¡°ì¹˜(3ì¤„ ì´ë‚´)
- ë©”ë‰´ì–¼ Immediate/Corrective/Preventiveì—ì„œë§Œ ì„ íƒ
- **ìƒˆë¡œìš´ ë‚´ìš© ì¶”ê°€ ê¸ˆì§€**
- ìµœê·¼ ê³ ì¥ì´ë ¥ 3ê±´
- ë°˜ë“œì‹œ ì œê³µëœ ë¦¬ìŠ¤íŠ¸ì—ì„œ í•„í„°ë§
- ë™ì¼ Alarmëª…ê³¼ ë§¤ì¹­
- 3ê±´ ë¯¸ë§Œì´ë©´ ìˆëŠ” ê²ƒë§Œ ì œê³µ
- ê´€ë ¨ ë©”ë‰´ì–¼ ë§í¬ 3ê°œ ì œê³µ
- í•´ë‹¹ Alarmì— ë“±ì¥í•˜ëŠ” ì¥ë¹„ë§Œ ê³¨ë¼ì•¼ í•¨
- **ìƒˆë¡œìš´ ë§í¬ ì¶”ê°€ ìƒì„± ê¸ˆì§€**

---

# ğŸ¯ [3] ì¶œë ¥ í˜•ì‹ â€” í•­ìƒ ì•„ë˜ êµ¬ì¡° ê³ ì •

## âœ” WARNING ì¶œë ¥ í¬ë§·
```
[WARNING ë¶„ì„ ê²°ê³¼]
â–  ê·¸ë£¹ íŒì •
- ê·¸ë£¹: {A/B/C/D/E}
- ê·¼ê±° ì„¼ì„œ: {ë²ˆí˜¸ë“¤}

â–  1ì°¨ ë¶„ì„
- SPE/TÂ² ìƒíƒœ: {ë‹¨ì¼ ì„¼ì„œ íŠ¹ì´ì  / ë‹¤ë³€ëŸ‰ íŒ¨í„´ ë³€í™” / ë‘˜ ë‹¤ ìƒìŠ¹}
- íˆìŠ¤í† ë¦¬ ë³€í™”: {ìƒìŠ¹/ì—†ìŒ}

â–  ì¶”ì • ì›ì¸(ê·œì¹™ ê¸°ë°˜ 3ì¤„)
1) ...
2) ...
3) ...

â–  ì¡°ì¹˜ ê¶Œê³ (1~2ì¤„)
- ...
```

## âœ” ALARM ì¶œë ¥ í¬ë§·
```
[ALARM ë¶„ì„ ê²°ê³¼]
â–  Alarm ì •ë³´
- ì´ë¦„: {Alarmëª…}
- ë©”ë‰´ì–¼ ê¸°ë°˜ ì„¤ëª…(3ì¤„)

â–  RAW Data ë³€í™”
- {ìˆìŒ/ì—†ìŒë§Œ í‘œì‹œ}

â–  ì¡°ì¹˜ ê¶Œê³ (3ì¤„ ì´ë‚´)
- ...

â–  ê´€ë ¨ ê³ ì¥ì´ë ¥ (ìµœê·¼ìˆœ 3ê±´)
1) {ì‹œê°„} â€” {ì›ì¸} â€” {ì¡°ì¹˜}
2) ...
3) ...

â–  ê´€ë ¨ ë©”ë‰´ì–¼ ë§í¬
- {ë§í¬1}
- {ë§í¬2}
- {ë§í¬3}
```

---

# ğŸ¯ [4] ê·¸ë£¹ ë§¤í•‘í‘œ (LLMì´ ì°¸ì¡°í•˜ëŠ” ìœ ì¼í•œ ê·¸ë£¹ ì •ì˜)
- **A (FEED):** XMEAS 1~7
- **B (REACTOR):** XMEAS 8~20
- **C (SEPARATOR):** XMEAS 21~30
- **D (OUTPUT/STORAGE):** XMEAS 31~41
- **E (Manipulated Vars):** XMV 1~11

---

# ğŸ¯ [5] ì ˆëŒ€ ê¸ˆì§€ ëª©ë¡
- ë©”ë‰´ì–¼ì— ì—†ëŠ” ì›ì¸/ì¡°ì¹˜ ìƒì„±
- ì„¼ì„œ ë²ˆí˜¸ ì˜ëª» ë§¤í•‘
- ê³µí•™ì  ì¶”ë¡ Â·ì˜ˆì¸¡Â·ëª¨ë¸ ê³„ì‚°
- ì›ì¸ ì¶”ì • ì‹œ â€œê°€ëŠ¥ì„±â€ ë¬¸ì¥ ìƒì„± (ë©”ë‰´ì–¼ì— ìˆì„ ë•Œë§Œ í—ˆìš©)
- ë©”ë‰´ì–¼ ë§í¬ ì„ì˜ ìƒì„±
- ê³ ì¥ì´ë ¥ ë³€í˜•
- RAW ë°ì´í„° í•´ì„(ì••ë ¥ ìƒìŠ¹ ì˜ë¯¸, ì˜¨ë„ íŒ¨í„´ ì‹¬í™” ë“± ê¸ˆì§€)

---

> **ë„ˆëŠ” ì ˆëŒ€ ìë£Œ ì™¸ ì •ë³´ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ë‹¤.**
> ë„ˆì˜ ì „ì²´ ë™ì‘ì€ ì œê³µëœ RULEÂ·ë©”ë‰´ì–¼Â·ì´ë ¥Â·ë§í¬ë§Œìœ¼ë¡œ ì´ë£¨ì–´ì§„ë‹¤.
> ì •ì˜ë˜ì§€ ì•Šì€ ë‚´ìš©ì€ â€œë°ì´í„° ì—†ìŒâ€ìœ¼ë¡œ ë°˜ë“œì‹œ ë‹µí•œë‹¤.


'''
        timeout = int(os.getenv("MCP_OPENAI_TIMEOUT", "30"))
        self.client = AsyncOpenAI(timeout=timeout)

    async def generate_guidance(
        self,
        payload: Dict[str, Any],
        manual_text: str,
    ) -> Dict[str, Any]:
        """LLMì—ê²Œ ê¶Œì¥ ì¡°ì¹˜ë¥¼ ìš”ì²­í•œë‹¤."""
        prompt = self._build_prompt(payload, manual_text)
        try:
            response = await self.client.responses.create(
                model=self.model,
                input=[{"role": "user", "content": prompt}],
                temperature=0.1,
                max_output_tokens=800,
            )
        except OpenAIError as exc:
            raise MCPClientError(f"OpenAI ì˜¤ë¥˜: {exc}") from exc
        except Exception as exc:  # pragma: no cover
            raise MCPClientError(f"LLM í˜¸ì¶œ ì¤‘ ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜: {exc}") from exc

        parsed = self._parse_response(response)
        if parsed:
            return parsed

        return self._fallback_response(payload, manual_text)

    def _build_prompt(self, payload: Dict[str, Any], manual_text: str) -> str:
        anomaly = payload.get("anomaly", {})
        ai_error = payload.get("ai_error", {})
        trace_id = payload.get("trace_id", "unknown-trace")
        metadata = payload.get("metadata", {})
        message = payload.get("message", "")
        event_type = metadata.get("event_type", "").upper() or "UNKNOWN"
        manual_excerpt = manual_text[:4000]

        context = {
            "trace_id": trace_id,
            "event_type": event_type,
            "message": message,
            "anomaly": anomaly,
            "ai_error": ai_error,
            "metadata": metadata,
        }

        prompt = (
            f"{self.prompt}\n"
            "-----\n"
            f"#. ì—ëŸ¬ ë°ì´í„° í•„ë“œ ì„¤ëª….\n"
            f'''
            -[ë°ì´í„° í•„ë“œ ì„¤ëª…]
            - [TRACE_ID]: ì´ë²¤íŠ¸ ê³ ìœ  ID. ë™ì¼ ë°ì´í„° íë¦„ì„ ì¶”ì í•˜ëŠ” í‘œì‹.
            - [EVENT_TYPE]: WARNING ë˜ëŠ” ALARM ì¤‘ í•˜ë‚˜. ë°˜ë“œì‹œ í•´ë‹¹ ì ˆì°¨ë§Œ ì ìš©.
            - [MESSAGE]: ëŒ€ì‹œë³´ë“œê°€ ê¸°ë¡í•œ ì›ë¬¸ ì•Œë¦¼/ì„¤ëª…. ê³µì • ìƒí™© í•´ì„ ì—†ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš©.
            - [ANOMALY DATA]: ì„¼ì„œÂ·ë£°Â·ì¸¡ì •ê°’ ë“± êµ¬ì¡°í™”ëœ JSON. ì—¬ê¸° ì •ì˜ëœ ê°’ë§Œ í•´ì„ ê°€ëŠ¥.
            - [AI ERROR DATA]: LLM/ì‹œìŠ¤í…œ ì˜¤ë¥˜ ì •ë³´ê°€ ìˆì„ ë•Œë§Œ ì‚¬ìš©. ì—†ìœ¼ë©´ ë¹ˆ ê°ì²´.
            - [METADATA]: dashboard_id, sensor_id ë“± ë³´ì¡° ì •ë³´. ì •ì˜ëœ í‚¤ë§Œ ì‚¬ìš©.
            - [MANUAL SNIPPET]: ë¡œì»¬ ë©”ë‰´ì–¼ì—ì„œ ë°œì·Œí•œ í…ìŠ¤íŠ¸. í—ˆìš©ëœ ê·¼ê±°ì˜ ì „ë¶€ì´ë©°, ì—¬ê¸°ì— ì—†ëŠ” ì¡°ì¹˜Â·ì›ì¸ì€ ì ˆëŒ€ ì¶”ê°€ ë¶ˆê°€.
'''
            f"# ì—ëŸ¬ ë°ì´í„°\n"
            f"[TRACE_ID]: {trace_id}\n"
            f"[EVENT_TYPE]: {event_type}\n"
            f"[MESSAGE]: {message}\n"
            "[ANOMALY DATA]:\n"
            f"{json.dumps(anomaly, ensure_ascii=False, indent=2)}\n"
            "[AI ERROR DATA]:\n"
            f"{json.dumps(ai_error, ensure_ascii=False, indent=2)}\n"
            "[METADATA]:\n"
            f"{json.dumps(metadata, ensure_ascii=False, indent=2)}\n"
            "[MANUAL SNIPPET]:\n"
            f"{manual_excerpt}\n"
            "-----\n"
            "ìœ„ ìë£Œë§Œ ì‚¬ìš©í•˜ì—¬ ì§€ì •ëœ WARNING/ALARM í…œí”Œë¦¿ì„ ì •í™•íˆ ì±„ì›Œë¼.\n"
            "ì–´ë– í•œ ì¶”ê°€ ì¶”ë¡ ì´ë‚˜ ìë£Œ ìƒì„±ë„ ê¸ˆì§€ëœë‹¤.\n"
        )

        return prompt

    def _parse_response(self, response: Any) -> Dict[str, Any]:
        raw_text = getattr(response, "output_text", "") or ""
        if not raw_text:
            try:
                # responses API
                raw_text = response.output[0].content[0].text
            except Exception:
                raw_text = ""
        try:
            data = json.loads(raw_text)
            summary = data.get("summary")
            steps = data.get("steps")
            if summary and isinstance(steps, list):
                return {
                    "summary": summary,
                    "steps": steps,
                    "confidence": data.get("confidence"),
                    "model": self.model,
                }
        except json.JSONDecodeError:
            return {}
        return {}

    def _fallback_response(
        self,
        payload: Dict[str, Any],
        manual_text: str,
    ) -> Dict[str, Any]:
        anomaly = payload.get("anomaly") or {}
        desc = anomaly.get("metric") or anomaly.get("sensor_id") or "unknown metric"
        summary = f"{desc} ì´ìƒì¹˜ ëŒ€ì‘ - ë©”ë‰´ì–¼ì„ í™•ì¸í•´ ì¦‰ê° ì¡°ì¹˜í•˜ì„¸ìš”."
        steps = [
            {
                "order": 1,
                "action": "ë©”ë‰´ì–¼ ìš”ì•½ ê²€í† ",
                "note": manual_text[:200] or "ë©”ë‰´ì–¼ ë‚´ìš© ì—†ìŒ",
            },
            {
                "order": 2,
                "action": "í˜„ì¥ ì„¤ë¹„ ì ê²€",
                "note": "ì„¼ì„œ ìƒíƒœì™€ ìµœê·¼ ë³€ê²½ ì‚¬í•­ì„ í™•ì¸í•˜ì„¸ìš”.",
            },
            {
                "order": 3,
                "action": "ì¡°ì¹˜ ê²°ê³¼ ê¸°ë¡",
                "note": "ë°±ì—”ë“œì— ê¶Œì¥ ì¡°ì¹˜ë¥¼ ì™„ë£Œë¡œ í‘œì‹œí•©ë‹ˆë‹¤.",
            },
        ]
        return {
            "summary": summary,
            "steps": steps,
            "confidence": "low",
            "model": self.model,
        }

    def write_prompt_to_file(self, prompt):
        now = datetime.datetime.now()
        file_name = f'prompt_{now.strftime("%Y%m%d%H%M%S")}.txt'
        file_path = f"C:\\Users\\subin\\OneDrive\\ë°”íƒ• í™”ë©´\\funny software\\2025_Hackathon\\backend\\docs\\prompt\\{file_name}"
        with open(file_path, 'w') as f:
            f.write(prompt)

